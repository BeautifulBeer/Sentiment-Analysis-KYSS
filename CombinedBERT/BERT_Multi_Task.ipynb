{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc83b08d",
   "metadata": {
    "id": "bc83b08d"
   },
   "source": [
    "# BERT Sentiment Classification\n",
    "## Applied Methodology\n",
    "- Multi-task learning\n",
    "\n",
    "## Available choices\n",
    "- Pretrained model : RoBERTa, BERT\n",
    "- Tasks : Kaggle, IMDB, Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vKZvqteNn03C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKZvqteNn03C",
    "outputId": "c901b333-e83b-49ee-f3c5-19033b665166"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchtext\n",
    "!pip3 install transformers\n",
    "!pip3 install tqdm\n",
    "!pip3 install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c80a86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "34c80a86",
    "outputId": "82f3d57e-81c6-4c6d-ee29-96fcfb711b94"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Label for Task\n",
    "SENTIMENT_LABEL = 'sentiment'\n",
    "IMDB_LABEL = 'imdb'\n",
    "SARCASM_LABEL = 'sarcasm'\n",
    "\n",
    "# Label for loss function\n",
    "CROSS_ENTROPY_LOSS_LABEL = 'crossentropyloss'\n",
    "\n",
    "# Configurations for running code\n",
    "configs = {\n",
    "    'path' : {\n",
    "        'colab' : {\n",
    "            'root' : '/content/gdrive/My Drive',\n",
    "            'data' : 'dataset',\n",
    "            'checkpoint' : 'checkpoints',\n",
    "        },\n",
    "        'local' : {\n",
    "            'root' : '../',\n",
    "            'data' : '.data',\n",
    "            'checkpoint' : 'checkpoints',\n",
    "        },   \n",
    "    },\n",
    "    'task' : {\n",
    "        SENTIMENT_LABEL : {\n",
    "            'train_file' : 'sentence-classification/train_final.csv',\n",
    "            'test_file' : 'sentence-classification/eval_final_open.csv',\n",
    "            'train_valid_frac' : 0.8,\n",
    "            'out_features' : 5,\n",
    "            'loss_fn' : CROSS_ENTROPY_LOSS_LABEL,\n",
    "        },\n",
    "        IMDB_LABEL : {\n",
    "            'train_file' : 'imdb/train_IM.csv',\n",
    "            'train_valid_frac' : 0.8,\n",
    "            'out_features' : 2,\n",
    "            'loss_fn' : CROSS_ENTROPY_LOSS_LABEL,\n",
    "        },\n",
    "        SARCASM_LABEL : {\n",
    "            'train_file' : 'reddit-sarcasm/train_sarcasm.csv',\n",
    "            'train_valid_frac' : 0.8,\n",
    "            'out_features' : 2,\n",
    "            'loss_fn' : CROSS_ENTROPY_LOSS_LABEL,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Value for each Task\n",
    "class Task(Enum):\n",
    "    SENTIMENT = 1\n",
    "    IMDB = 2\n",
    "    SARCASM = 3\n",
    "\n",
    "# To store trained model's checkpoint(filename)\n",
    "start_time = datetime.now()\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    root_dir = Path(configs['path']['colab']['root'])\n",
    "    data_dir = Path(root_dir, configs['path']['colab']['data'])\n",
    "    checkpoint_dir = Path(root_dir, configs['path']['colab']['checkpoint'])\n",
    "\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    \n",
    "    root_dir = Path(configs['path']['local']['root'])\n",
    "    data_dir = Path(root_dir, configs['path']['local']['data'])\n",
    "    checkpoint_dir = Path(root_dir, configs['path']['local']['checkpoint'])\n",
    "\n",
    "Path(checkpoint_dir).mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "# Load pretrained model\n",
    "PRETRAINED_MODEL = 'bert-base-cased'\n",
    "\n",
    "if re.compile('^robert').match(PRETRAINED_MODEL):\n",
    "    from transfomers import RobertaModel, RobertaTokenizer, AdamW\n",
    "    \n",
    "    tokenizer = RobertaTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "    bert_model = RobertaModel.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "elif re.compile('^bert').match(PRETRAINED_MODEL):\n",
    "    from transfomers import BertTokenizer, BertModel, AdamW\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "    bert_model = BertModel.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a8112",
   "metadata": {
    "id": "c72a8112"
   },
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12018ad",
   "metadata": {
    "id": "a12018ad"
   },
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "  '''\n",
    "    Preprocessing dataframe to dataset. CSV should have two columns : \"Sentence\", \"Category\"\n",
    "    :params\n",
    "      df: dataframe loaded from csv\n",
    "      task: value for each task - reference class Task(Enum)\n",
    "  '''\n",
    "    def __init__(self, df, task, tokenizer, max_len, is_train):\n",
    "        self.task = task\n",
    "        self.sentences = df['Sentence'].to_numpy()\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.targets = df['Category'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        if self.is_train:\n",
    "            target = self.targets[idx]\n",
    "               \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens = True, # Add CLS, SEP\n",
    "            max_length = self.max_len,\n",
    "            return_token_type_ids = False,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "        )\n",
    "        if self.is_train:\n",
    "            return {\n",
    "                'task' : self.task,\n",
    "                'text' : sentence,\n",
    "                'input_ids' : encoding['input_ids'].flatten(),\n",
    "                'attention_mask' : encoding['attention_mask'].flatten(),\n",
    "                'targets' : torch.tensor(target, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'task' :self.task,\n",
    "                'text' : sentence,\n",
    "                'input_ids' : encoding['input_ids'].flatten(),\n",
    "                'attention_mask' : encoding['attention_mask'].flatten(),\n",
    "            }\n",
    "\n",
    "def load_csv_data(configs, seed):\n",
    "  '''\n",
    "    Return dictionary of dataframes for each task from csv\n",
    "    :return\n",
    "      dict, dict, dict: train, valid, test dataset is returned. Task label is key (e.g. SENTIMENT_LABEL)\n",
    "  '''\n",
    "    train_data = {}\n",
    "    valid_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for task in configs['task']:\n",
    "        raw_data = pd.read_csv(data_dir.joinpath(configs['task'][task]['train_file']))\n",
    "        if task == 'imdb':\n",
    "            raw_data.rename(columns = {'Phrase': 'Sentence', 'Sentiment': 'Category'}, inplace=True)\n",
    "        train_data[task] = raw_data.sample(frac=configs['task'][task]['train_valid_frac'], random_state=seed)\n",
    "        valid_data[task] = raw_data.drop(train_data[task].index)\n",
    "        if 'test_file' in configs['task'][task]:\n",
    "            test_data[task] = pd.read_csv(data_dir.joinpath(configs['task'][task]['test_file']))\n",
    "            if task == 'imdb':\n",
    "                test_data[task].rename(columns = {'Phrase': 'Sentence', 'Sentiment': 'Category'}, inplace=True)\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "def print_dataset_configs(configs, train, valid, test):\n",
    "  '''\n",
    "    Print overview of preprocessed dataset\n",
    "  '''\n",
    "    for task in train:\n",
    "        print(f'{task} dataset')\n",
    "        print(f'='*25)\n",
    "        print(f'Train/Valid : {configs[\"task\"][task][\"train_valid_frac\"]:.2f}/{1-configs[\"task\"][task][\"train_valid_frac\"]:.2f}')\n",
    "        print(f'='*25)\n",
    "        print(f'Train dataset length : {len(train[task])}')\n",
    "        if task in valid:\n",
    "            print(f'Valid dataset length : {len(valid[task])}')\n",
    "        if task in test:\n",
    "            print(f'Test dataset length : {len(test[task])}')\n",
    "        print(f'='*25)\n",
    "        print('')\n",
    "\n",
    "def get_data_loader(phase, task_df, tokenizer, max_len, batch_size, is_train, shuffle):\n",
    "  '''\n",
    "    Get an entire dataloader. Each dataset of a task is preprocessed under the same conditions (e.g. batch_size)\n",
    "    :params\n",
    "      task_df: dataset for each task, dataframe\n",
    "  '''\n",
    "    total_dataset = []\n",
    "    \n",
    "    for task in task_df:\n",
    "        dataset = ClassificationDataset(\n",
    "            task_df[task],\n",
    "            convert_label_to_enum(task),\n",
    "            tokenizer = tokenizer,\n",
    "            max_len = max_len,\n",
    "            is_train=is_train,\n",
    "        )\n",
    "        time.sleep(1)\n",
    "        \n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "        \n",
    "        print(f'Combine {phase} - {task} dataset')\n",
    "        time.sleep(1)\n",
    "        for batch in tqdm(loader):\n",
    "            total_dataset.append(batch)\n",
    "    \n",
    "    return DataLoader(\n",
    "        total_dataset,\n",
    "        shuffle = shuffle,\n",
    "        batch_size = 1,\n",
    "    )\n",
    "\n",
    "def convert_enum_to_label(enum):\n",
    "    if enum == Task.SENTIMENT.value:\n",
    "        return SENTIMENT_LABEL\n",
    "    elif enum == Task.IMDB.value:\n",
    "        return IMDB_LABEL\n",
    "    elif enum == Task.SARCASM.value:\n",
    "        return SARCASM_LABEL\n",
    "\n",
    "def convert_label_to_enum(label):\n",
    "    if label == SENTIMENT_LABEL:\n",
    "        return Task.SENTIMENT.value\n",
    "    elif label == IMDB_LABEL:\n",
    "        return Task.IMDB.value\n",
    "    elif label == SARCASM_LABEL:\n",
    "        return Task.SARCASM.value\n",
    "    \n",
    "def convert_name_to_func(name):\n",
    "    if name == CROSS_ENTROPY_LOSS_LABEL:\n",
    "        return nn.CrossEntropyLoss()\n",
    "    elif name == BCE_LOSS_WITH_LOGITS_LABEL:\n",
    "        return nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e8dee",
   "metadata": {},
   "source": [
    "## Define model, Train, Valid, Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ca67a",
   "metadata": {
    "id": "645ca67a"
   },
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "  '''\n",
    "    Multi-task learning is applied\n",
    "    fc_sent, fc_im, fc_sarc is fully connected layer of each task and train separately. (share BERT layer)\n",
    "  '''\n",
    "    def __init__(self, bert, configs, dropout_p):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout_p = dropout_p\n",
    "        hidden_size = bert.config.to_dict()['hidden_size']\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        \n",
    "        if SENTIMENT_LABEL in configs['task']:\n",
    "            self.fc_sent = nn.Linear(\n",
    "                hidden_size,\n",
    "                configs['task'][SENTIMENT_LABEL]['out_features'],\n",
    "            )\n",
    "        \n",
    "        if IMDB_LABEL in configs['task']:\n",
    "            self.fc_im = nn.Linear(\n",
    "                hidden_size,\n",
    "                configs['task'][IMDB_LABEL]['out_features'],\n",
    "            )\n",
    "\n",
    "        if SARCASM_LABEL in configs['task']:\n",
    "            self.fc_sarc = nn.Linear(\n",
    "                hidden_size,\n",
    "                configs['task'][SARCASM_LABEL]['out_features'],\n",
    "            )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, target_task):\n",
    "    '''\n",
    "      forward for each task\n",
    "      :params\n",
    "        target_task: task label(string)\n",
    "    '''\n",
    "        result = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask\n",
    "        )\n",
    "        out = self.dropout(result.pooler_output)\n",
    "\n",
    "        if target_task == SENTIMENT_LABEL:\n",
    "            out = self.fc_sent(out)\n",
    "        elif target_task == IMDB_LABEL:\n",
    "            out = self.fc_im(out)\n",
    "        elif target_task == SARCASM_LABEL:\n",
    "            out = self.fc_sarc(out)\n",
    "        \n",
    "        if not self.train:\n",
    "            out = out * (1-self.dropout_p)\n",
    "\n",
    "        return out\n",
    "\n",
    "def train_epoch(model, loader, loss_fn, optimizer, scheduler, dataset_size):    \n",
    "    losses = {}\n",
    "    means = {}\n",
    "    correct_predictions = {}\n",
    "    \n",
    "    for task in loss_fn:\n",
    "        losses[task] = []\n",
    "        correct_predictions[task] = 0.0\n",
    "    \n",
    "    model = model.train()\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'][0]\n",
    "        attention_mask = batch['attention_mask'][0]\n",
    "        targets = batch['targets'][0]\n",
    "        task = convert_enum_to_label(batch['task'][0][0])\n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            target_task = task,\n",
    "        )\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn[task](outputs, targets)\n",
    "        \n",
    "        correct_predictions[task] += torch.sum(preds == targets)\n",
    "        losses[task].append(loss.detach().item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    for task in correct_predictions:\n",
    "        correct_predictions[task] = correct_predictions[task].double() / dataset_size[task]\n",
    "        means[task] = np.sum(losses[task]) / dataset_size[task]\n",
    "        \n",
    "    return correct_predictions, losses, means\n",
    "\n",
    "def valid_epoch(model, loader, loss_fn, dataset_size):\n",
    "    losses = {}\n",
    "    means = {}\n",
    "    correct_predictions = {}\n",
    "\n",
    "    for task in loss_fn:\n",
    "        losses[task] = []\n",
    "        correct_predictions[task] = 0.0\n",
    "    \n",
    "    model = model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            input_ids = batch['input_ids'][0]\n",
    "            attention_mask = batch['attention_mask'][0]\n",
    "            targets = batch['targets'][0]\n",
    "            task = convert_enum_to_label(batch['task'][0][0])\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input_ids = input_ids.cuda()\n",
    "                attention_mask = attention_mask.cuda()\n",
    "                targets = targets.cuda()\n",
    "                \n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                target_task = task\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            loss = loss_fn[task](outputs, targets)\n",
    "            \n",
    "            correct_predictions[task] += torch.sum(preds == targets)\n",
    "            losses[task].append(loss.detach().item())\n",
    "\n",
    "        for task in correct_predictions:\n",
    "            correct_predictions[task] = correct_predictions[task].double() / dataset_size[task]\n",
    "            means[task] = np.sum(losses[task]) / dataset_size[task] \n",
    "\n",
    "    return correct_predictions, losses, means\n",
    "\n",
    "def get_predictions(model, loader, task):\n",
    "    model = model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    predictions_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'][0]\n",
    "            attention_mask = batch['attention_mask'][0]\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input_ids = input_ids.cuda()\n",
    "                attention_mask = attention_mask.cuda()\n",
    "                \n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                target_task = task\n",
    "            )         \n",
    "            predictions.extend(torch.argmax(outputs, dim=1))\n",
    "            \n",
    "    return torch.stack(predictions).cpu()\n",
    "\n",
    "\n",
    "def print_model_results(phase, epoch, accuracy, losses):\n",
    "    for task in accuracy:\n",
    "        print(f'{phase} : {task} accruacy/loss : {accuracy[task]:.5f}/{losses[task]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9862eae",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 884532\n",
    "# For same result\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_len = 100\n",
    "batch_size = 8\n",
    "\n",
    "train_data, valid_data, test_data = load_csv_data(configs, RANDOM_SEED)\n",
    "\n",
    "\n",
    "print(f'Batch size = {batch_size}')\n",
    "print(f'-'*50)\n",
    "print(f'Task Configuration')\n",
    "print(f'-'*50)\n",
    "print_dataset_configs(configs, train_data, valid_data, test_data)\n",
    "print(f'-'*50)\n",
    "\n",
    "train_loader = get_data_loader('Train', train_data, tokenizer, max_len, batch_size, True, True)\n",
    "valid_loader = get_data_loader('Valid', valid_data, tokenizer, max_len, batch_size, True, True)\n",
    "test_loader = get_data_loader('Test', test_data, tokenizer, max_len, batch_size, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd8b825",
   "metadata": {},
   "source": [
    "### Train, Valid, Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcf9f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524,
     "referenced_widgets": [
      "35fe81508cf1479dbc24e3712dad6ba9",
      "c6cfc5ccbaef454998ea9bf539c23af1",
      "9f9e98e1c92143b8aba4bebeff152851",
      "544b7ef82cbb4e71a6e950c287e261a0",
      "f768be88af6f4ed89df2ae210110239c",
      "b6b5e1f8003b4d7399b4c780627f5744",
      "cf446dd25aea4add8d165fca358b0d88",
      "7c06a1a24867458a99972e4940814cd8",
      "7100da52f3054937ad724299b5c54e02",
      "edb2cf11e9a84d838c7421cec6cb10b5",
      "efdc0d5a7ce742429283643f8802cc59",
      "207e44f46e7d4efd86cf4f5fef7be349",
      "06fdc91ee22549cc8e2289b025ade5a9",
      "f0be942cae5e4304adec71a85be2e9ca",
      "8a76997b1f5e4bb7b3831e0c7a8c6e2f",
      "031bf866e07b4b36bd1ff5226c85c627"
     ]
    },
    "id": "35fcf9f4",
    "outputId": "b43ec4f4-33a7-4255-c3e8-fc417af8ed0d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SentimentModel(bert_model, configs, 0.1)\n",
    "\n",
    "epochs = 10\n",
    "total_steps = len(train_loader) * epochs\n",
    "learning_rate = 2e-5\n",
    "\n",
    "loss_fn = {}\n",
    "train_size = {}\n",
    "valid_size = {}\n",
    "\n",
    "for task in configs['task']:\n",
    "    loss_fn[task] = convert_name_to_func(configs['task'][task]['loss_fn'])\n",
    "    train_size[task] = len(train_data[task])\n",
    "    valid_size[task] = len(valid_data[task])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    for task in loss_fn:\n",
    "        # model fully connected layer cuda\n",
    "        loss_fn[task] = loss_fn[task].cuda()\n",
    "    \n",
    "# Adam optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Cosine annealing warm restarts\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0 = int(epochs / 3),\n",
    "    T_mult = 1,\n",
    "    eta_min = 2e-8\n",
    ")\n",
    "\n",
    "results = {\n",
    "    'train_loss' : [],\n",
    "    'train_acc' : [],\n",
    "    'valid_loss' : [],\n",
    "    'valid_acc' : []\n",
    "}\n",
    "\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} / {epochs}')\n",
    "    time.sleep(1)\n",
    "    train_acc, train_loss, train_loss_mean = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        train_size\n",
    "    )\n",
    "    print_model_results('Train', epoch, train_acc, train_loss_mean)\n",
    "    results['train_loss'].append(train_loss)\n",
    "    results['train_acc'].append(train_acc)\n",
    "    time.sleep(1)\n",
    "    valid_acc, valid_loss, valid_loss_mean = valid_epoch(\n",
    "        model,\n",
    "        valid_loader,\n",
    "        loss_fn,\n",
    "        valid_size\n",
    "    ) \n",
    "    print_model_results('Valid', epoch, valid_acc, valid_loss_mean)\n",
    "    results['valid_loss'].append(valid_loss)\n",
    "    results['valid_acc'].append(valid_acc)\n",
    "    \n",
    "    if best_valid_acc < valid_acc[SENTIMENT_LABEL]:\n",
    "        best_valid_acc = valid_acc[SENTIMENT_LABEL]\n",
    "        torch.save(model.state_dict(), Path(checkpoint_dir, f'Model_Valid_{start_time.strftime(\"%Y_%m_%d_%H_%M_%S\")}.pt'))\n",
    "        print(f'Best valid acc : {best_valid_acc * 100:.5f}%')\n",
    "        \n",
    "    print(f'-'*25)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), Path(checkpoint_dir, f'Model_Train_{start_time.strftime(\"%Y_%m_%d_%H_%M_%S\")}.pt'))\n",
    "model.load_state_dict(torch.load(Path(checkpoint_dir, f'Model_Valid_{start_time.strftime(\"%Y_%m_%d_%H_%M_%S\")}.pt')))\n",
    "predictions = get_predictions(model, test_loader, SENTIMENT_LABEL)\n",
    "\n",
    "submission = pd.DataFrame({'Id' : range(len(predictions)), 'Category' : predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Multi_Task.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "031bf866e07b4b36bd1ff5226c85c627": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06fdc91ee22549cc8e2289b025ade5a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "207e44f46e7d4efd86cf4f5fef7be349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_031bf866e07b4b36bd1ff5226c85c627",
      "placeholder": "​",
      "style": "IPY_MODEL_8a76997b1f5e4bb7b3831e0c7a8c6e2f",
      "value": " 4203/26809 [02:20&lt;11:39, 32.33it/s]"
     }
    },
    "35fe81508cf1479dbc24e3712dad6ba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f9e98e1c92143b8aba4bebeff152851",
       "IPY_MODEL_544b7ef82cbb4e71a6e950c287e261a0"
      ],
      "layout": "IPY_MODEL_c6cfc5ccbaef454998ea9bf539c23af1"
     }
    },
    "544b7ef82cbb4e71a6e950c287e261a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c06a1a24867458a99972e4940814cd8",
      "placeholder": "​",
      "style": "IPY_MODEL_cf446dd25aea4add8d165fca358b0d88",
      "value": " 107233/107233 [3:30:19&lt;00:00,  8.50it/s]"
     }
    },
    "7100da52f3054937ad724299b5c54e02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efdc0d5a7ce742429283643f8802cc59",
       "IPY_MODEL_207e44f46e7d4efd86cf4f5fef7be349"
      ],
      "layout": "IPY_MODEL_edb2cf11e9a84d838c7421cec6cb10b5"
     }
    },
    "7c06a1a24867458a99972e4940814cd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a76997b1f5e4bb7b3831e0c7a8c6e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f9e98e1c92143b8aba4bebeff152851": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6b5e1f8003b4d7399b4c780627f5744",
      "max": 107233,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f768be88af6f4ed89df2ae210110239c",
      "value": 107233
     }
    },
    "b6b5e1f8003b4d7399b4c780627f5744": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6cfc5ccbaef454998ea9bf539c23af1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf446dd25aea4add8d165fca358b0d88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edb2cf11e9a84d838c7421cec6cb10b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efdc0d5a7ce742429283643f8802cc59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 16%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0be942cae5e4304adec71a85be2e9ca",
      "max": 26809,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_06fdc91ee22549cc8e2289b025ade5a9",
      "value": 4203
     }
    },
    "f0be942cae5e4304adec71a85be2e9ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f768be88af6f4ed89df2ae210110239c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
