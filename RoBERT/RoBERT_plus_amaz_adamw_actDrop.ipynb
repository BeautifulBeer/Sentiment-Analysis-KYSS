{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "# For same result\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('.')\n",
    "data_dir = Path(root_dir,'.data', 'sentence-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, is_train):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Phrase\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.targets = self.data.Sentiment\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        if self.is_train:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "def get_data_loader(df, tokenizer, max_len, batch_size, is_train, shuffle):\n",
    "    dataset = SentimentData(\n",
    "        df,\n",
    "        tokenizer = tokenizer,\n",
    "        max_len = max_len,\n",
    "        is_train=is_train,\n",
    "    )\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        shuffle = shuffle,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "def get_predictions(model, loader):\n",
    "    model = model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    predictions_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['ids']\n",
    "            attention_mask = batch['mask']\n",
    "            token_type_ids = batch[\"token_type_ids\"]\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                input_ids = input_ids.cuda()\n",
    "                attention_mask = attention_mask.cuda()\n",
    "                token_type_ids = token_type_ids.cuda()\n",
    "                \n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "                        \n",
    "            predictions.extend(outputs.detach().cpu().numpy())\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = torch.from_numpy(predictions)\n",
    "    return F.softmax(predictions,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Configuration\n",
      "-------------------------\n",
      "Train/Valid = 0.80/0.20\n",
      "Batch size = 8\n",
      "-------------------------\n",
      "Test set : 4311\n"
     ]
    }
   ],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 8\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "train_valid_frac = 0.8\n",
    "#원래 데이터셋\n",
    "train = pd.read_csv(data_dir.joinpath('train_plus.csv'))\n",
    "new_df = train[['Phrase', 'Sentiment']]\n",
    "\n",
    "# train_df=new_df.sample(frac=train_valid_frac,random_state=200)\n",
    "# valid_df=new_df.drop(train_df.index).reset_index(drop=True)\n",
    "# train_df = train_df.reset_index(drop=True)\n",
    "train_amazon_df = pd.read_csv(data_dir.joinpath('merged_250742_train_plus.csv'))\n",
    "train_amazon_df.rename(columns = {'Sentence': 'Phrase','Category':'Sentiment'}, inplace = True)\n",
    "\n",
    "test_df = pd.read_csv(data_dir.joinpath('eval_final_open.csv'))\n",
    "test_df = test_df[['Sentence']]\n",
    "test_df.rename(columns = {'Sentence': 'Phrase'}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Dataset Configuration')\n",
    "print(f'-'*25)\n",
    "print(f'Train/Valid = {train_valid_frac:.2f}/{1-train_valid_frac:.2f}')\n",
    "print(f'Batch size = {batch_size}')\n",
    "print(f'-'*25)\n",
    "# print(f'Train set : {len(train_df)}')\n",
    "# print(f'Valid set : {len(valid_df)}')\n",
    "print(f'Test set : {len(test_df)}')\n",
    "\n",
    "training_amazon_loader = get_data_loader(train_amazon_df, tokenizer, max_len, batch_size, True, True)\n",
    "training_loader        = get_data_loader(new_df, tokenizer, max_len, batch_size, True, True)\n",
    "# validating_loader = get_data_loader(valid_df, tokenizer, max_len, batch_size, True, True)\n",
    "testing_loader         = get_data_loader(test_df, tokenizer, max_len, batch_size, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveDropout(Module):\n",
    "    # all building blocks of networks are inherited from Module!\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()  # init the base class\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input):\n",
    "        mask = torch.rand_like(input) > self.p\n",
    "        return input * mask.to(input) / (1 - self.p)\n",
    "    \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier1 = torch.nn.Linear(768, 768)\n",
    "        self.pre_classifier2 = torch.nn.Linear(768, 768)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        \n",
    "        pooler = self.pre_classifier1(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = ActiveDropout(0.5)(pooler)\n",
    "        \n",
    "        pooler = self.pre_classifier2(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = ActiveDropout(0.5)(pooler)\n",
    "        \n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (pre_classifier2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = False\n",
    "model = RobertaClass()\n",
    "if load_model:\n",
    "    model = torch.load('pytorch_roberta_sentiment_plus_bay_sche_reg_layerdiff.bin')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch,data_loader):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(data_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "#         print(ids.shape)\n",
    "#         print(mask.shape)\n",
    "#         print(token_type_ids.shape)\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 1.6051499843597412\n",
      "Training Accuracy per 5000 steps: 12.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:34,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.8655217238674877\n",
      "Training Accuracy per 5000 steps: 65.31193761247751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:59,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.8087959946991324\n",
      "Training Accuracy per 5000 steps: 67.63198680131987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [37:32,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7850879310596054\n",
      "Training Accuracy per 5000 steps: 68.61542563829079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20001it [50:03,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7722809372526498\n",
      "Training Accuracy per 5000 steps: 69.05842207889606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25001it [1:02:27,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.761721469306356\n",
      "Training Accuracy per 5000 steps: 69.50021999120035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [1:14:56,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7513428106126712\n",
      "Training Accuracy per 5000 steps: 69.90058664711177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:27:19,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7433907517168753\n",
      "Training Accuracy per 5000 steps: 70.20120853689895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:39:46,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.7375545800889813\n",
      "Training Accuracy per 5000 steps: 70.40292742681433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42251it [1:45:20,  6.68it/s]\n",
      "1it [00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 70.49168202649089\n",
      "Training Loss Epoch: 0.7353461508836152\n",
      "Training Accuracy Epoch: 70.49168202649089\n",
      "Training Loss per 5000 steps: 0.7684475183486938\n",
      "Training Accuracy per 5000 steps: 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:33,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6530754551190158\n",
      "Training Accuracy per 5000 steps: 73.86022795440911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [25:03,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6522816746105385\n",
      "Training Accuracy per 5000 steps: 73.92885711428858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [37:25,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6534944338231442\n",
      "Training Accuracy per 5000 steps: 73.86590893940404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20001it [49:48,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6533003692894177\n",
      "Training Accuracy per 5000 steps: 73.79006049697516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25001it [1:02:14,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6521449746984748\n",
      "Training Accuracy per 5000 steps: 73.84704611815528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [1:14:37,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6521836793088229\n",
      "Training Accuracy per 5000 steps: 73.86212126262458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:27:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6526402737011361\n",
      "Training Accuracy per 5000 steps: 73.82753349904289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:39:21,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6519170047540734\n",
      "Training Accuracy per 5000 steps: 73.8678408039799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42251it [1:44:54,  6.71it/s]\n",
      "1it [00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 73.87094197388781\n",
      "Training Loss Epoch: 0.6516713769557353\n",
      "Training Accuracy Epoch: 73.87094197388781\n",
      "Training Loss per 5000 steps: 0.2530962824821472\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:20,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5991394397596125\n",
      "Training Accuracy per 5000 steps: 75.76484703059388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:46,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5992067103711751\n",
      "Training Accuracy per 5000 steps: 76.00239976002399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [37:08,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6009400310853439\n",
      "Training Accuracy per 5000 steps: 75.96410239317379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20001it [49:31,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.602868899504664\n",
      "Training Accuracy per 5000 steps: 75.9330783460827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25001it [1:02:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6050752728283739\n",
      "Training Accuracy per 5000 steps: 75.86946522139114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [1:14:31,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6064140887531838\n",
      "Training Accuracy per 5000 steps: 75.8245558481384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:26:54,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6072800044007705\n",
      "Training Accuracy per 5000 steps: 75.76319248021485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:39:18,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6079531089319826\n",
      "Training Accuracy per 5000 steps: 75.73748156296092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42251it [1:44:52,  6.71it/s]\n",
      "1it [00:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 75.71175403768605\n",
      "Training Loss Epoch: 0.608197566835292\n",
      "Training Accuracy Epoch: 75.71175403768605\n",
      "Training Loss per 5000 steps: 0.4047917127609253\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:26,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5530551374129917\n",
      "Training Accuracy per 5000 steps: 78.28434313137373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:56,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5568137625052612\n",
      "Training Accuracy per 5000 steps: 77.97095290470953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [37:26,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5611250558465125\n",
      "Training Accuracy per 5000 steps: 77.78814745683621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20001it [49:55,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5622340045354541\n",
      "Training Accuracy per 5000 steps: 77.69986500674966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25001it [1:02:25,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5642322632231015\n",
      "Training Accuracy per 5000 steps: 77.55439782408703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [1:14:49,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.56530447704729\n",
      "Training Accuracy per 5000 steps: 77.51033298890037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:27:09,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5663848547485517\n",
      "Training Accuracy per 5000 steps: 77.46778663466758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:39:29,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5680275110900439\n",
      "Training Accuracy per 5000 steps: 77.3980650483738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42251it [1:45:02,  6.70it/s]\n",
      "1it [00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 77.34872175690748\n",
      "Training Loss Epoch: 0.5689694656800263\n",
      "Training Accuracy Epoch: 77.34872175690748\n",
      "Training Loss per 5000 steps: 0.4931042790412903\n",
      "Training Accuracy per 5000 steps: 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:19,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5128838617352397\n",
      "Training Accuracy per 5000 steps: 79.66406718656269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:39,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5185211710911216\n",
      "Training Accuracy per 5000 steps: 79.4920507949205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15001it [36:59,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5199662732861503\n",
      "Training Accuracy per 5000 steps: 79.39804013065796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20001it [49:19,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5238518017782295\n",
      "Training Accuracy per 5000 steps: 79.26853657317135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25001it [1:01:39,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5261669388813272\n",
      "Training Accuracy per 5000 steps: 79.17133314667413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30001it [1:13:59,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.527892843827636\n",
      "Training Accuracy per 5000 steps: 79.09528015732809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:26:19,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5300371684040877\n",
      "Training Accuracy per 5000 steps: 79.00774263592469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:38:39,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5310726997807775\n",
      "Training Accuracy per 5000 steps: 78.91896452588685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42251it [1:44:12,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 78.84515817906941\n",
      "Training Loss Epoch: 0.5321142314766929\n",
      "Training Accuracy Epoch: 78.84515817906941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch,training_amazon_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n",
      "This tutorial is completed\n"
     ]
    }
   ],
   "source": [
    "output_model_file = 'DataPlus_ActDrop_Amazon.pt'\n",
    "torch.save(model, output_model_file)\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.6044201850891113\n",
      "Training Accuracy per 5000 steps: 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:24,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5527861642620905\n",
      "Training Accuracy per 5000 steps: 77.54199160167967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:46,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.55878471525131\n",
      "Training Accuracy per 5000 steps: 77.15353464653535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10908it [27:00,  6.73it/s]\n",
      "1it [00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 77.12609298541157\n",
      "Training Loss Epoch: 0.5586654354145714\n",
      "Training Accuracy Epoch: 77.12609298541157\n",
      "Training Loss per 5000 steps: 0.281051903963089\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:22,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.48335698994919074\n",
      "Training Accuracy per 5000 steps: 80.1114777044591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:44,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.4964902040193545\n",
      "Training Accuracy per 5000 steps: 79.48205179482052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10908it [26:59,  6.74it/s]\n",
      "1it [00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 79.41233769954505\n",
      "Training Loss Epoch: 0.4978523355835948\n",
      "Training Accuracy Epoch: 79.41233769954505\n",
      "Training Loss per 5000 steps: 0.4385903477668762\n",
      "Training Accuracy per 5000 steps: 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:22,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.4368876258045036\n",
      "Training Accuracy per 5000 steps: 82.15606878624276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:45,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.44728611560039083\n",
      "Training Accuracy per 5000 steps: 81.56559344065593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10908it [27:00,  6.73it/s]\n",
      "1it [00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 81.44646520209487\n",
      "Training Loss Epoch: 0.449355002094455\n",
      "Training Accuracy Epoch: 81.44646520209487\n",
      "Training Loss per 5000 steps: 0.2766173183917999\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:22,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.39146208056892884\n",
      "Training Accuracy per 5000 steps: 83.6882623475305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:44,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.4051711174446459\n",
      "Training Accuracy per 5000 steps: 83.07794220577942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10908it [26:59,  6.74it/s]\n",
      "1it [00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 82.96375242089823\n",
      "Training Loss Epoch: 0.40774703004455853\n",
      "Training Accuracy Epoch: 82.96375242089823\n",
      "Training Loss per 5000 steps: 0.3174186050891876\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:32,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.3574681064520695\n",
      "Training Accuracy per 5000 steps: 84.91051789642071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [24:56,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.36906550951508227\n",
      "Training Accuracy per 5000 steps: 84.50529947005299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10908it [27:10,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 84.37217084379047\n",
      "Training Loss Epoch: 0.3713701117911769\n",
      "Training Accuracy Epoch: 84.37217084379047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch,training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n",
      "This tutorial is completed\n"
     ]
    }
   ],
   "source": [
    "output_model_file = 'DataPlus_ActDrop_Amazon_fine.pt'\n",
    "torch.save(model, output_model_file)\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,var = MC_soft_predict(model,testing_loader,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(mean,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id' : range(len(result)), 'Category' : result})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n",
      "This tutorial is completed\n"
     ]
    }
   ],
   "source": [
    "output_model_file = 'DataPlus_ActDrop_Amazon.pt'\n",
    "torch.save(model, output_model_file)\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_np의 shape :  (100, 4311)\n",
      "pred_mean의 shape :  (4311,)\n",
      "Training Loss per 5000 steps: 0.34587007761001587\n",
      "Training Accuracy per 5000 steps: 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.42064276596386274\n",
      "Training Accuracy per 5000 steps: 84.03193612774452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:20,  6.69it/s]\n",
      "1it [00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 83.94803989793552\n",
      "Training Loss Epoch: 0.4239485210053111\n",
      "Training Accuracy Epoch: 83.94803989793552\n",
      "Training Loss per 5000 steps: 0.18421965837478638\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.2735056445121527\n",
      "Training Accuracy per 5000 steps: 89.94510978043913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.54it/s]\n",
      "1it [00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 89.95592669914173\n",
      "Training Loss Epoch: 0.273627813791438\n",
      "Training Accuracy Epoch: 89.95592669914173\n",
      "Training Loss per 5000 steps: 0.3439411520957947\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.1956560972524052\n",
      "Training Accuracy per 5000 steps: 93.28842315369262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.83it/s]\n",
      "1it [00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 93.15704012990025\n",
      "Training Loss Epoch: 0.19839738311629626\n",
      "Training Accuracy Epoch: 93.15704012990025\n",
      "Training Loss per 5000 steps: 0.027065671980381012\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.15148646134266003\n",
      "Training Accuracy per 5000 steps: 94.81037924151697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:20,  6.69it/s]\n",
      "1it [00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 94.75759684527952\n",
      "Training Loss Epoch: 0.1541372680075895\n",
      "Training Accuracy Epoch: 94.75759684527952\n",
      "Training Loss per 5000 steps: 0.012414940632879734\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.115831512902973\n",
      "Training Accuracy per 5000 steps: 96.28243512974052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.91it/s]\n",
      "1it [00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 96.3813500347947\n",
      "Training Loss Epoch: 0.11424061398459029\n",
      "Training Accuracy Epoch: 96.3813500347947\n",
      "Training Loss per 5000 steps: 0.021455349400639534\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.1088164110334326\n",
      "Training Accuracy per 5000 steps: 96.6067864271457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.91it/s]\n",
      "1it [00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 96.40454650893064\n",
      "Training Loss Epoch: 0.11065660176430665\n",
      "Training Accuracy Epoch: 96.40454650893064\n",
      "Training Loss per 5000 steps: 0.006005537696182728\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.09280202209767319\n",
      "Training Accuracy per 5000 steps: 97.1556886227545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.91it/s]\n",
      "1it [00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 97.0308513106008\n",
      "Training Loss Epoch: 0.0944573661258033\n",
      "Training Accuracy Epoch: 97.0308513106008\n",
      "Training Loss per 5000 steps: 0.012144832871854305\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.09100587407527622\n",
      "Training Accuracy per 5000 steps: 97.2554890219561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.91it/s]\n",
      "1it [00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 97.28601252609603\n",
      "Training Loss Epoch: 0.0899555188284475\n",
      "Training Accuracy Epoch: 97.28601252609603\n",
      "Training Loss per 5000 steps: 0.03976099565625191\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.07490814791131624\n",
      "Training Accuracy per 5000 steps: 97.65469061876247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.91it/s]\n",
      "1it [00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 97.58756668986314\n",
      "Training Loss Epoch: 0.07604199268074156\n",
      "Training Accuracy Epoch: 97.58756668986314\n",
      "Training Loss per 5000 steps: 0.011219233274459839\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.06029457824714594\n",
      "Training Accuracy per 5000 steps: 98.22854291417165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:17,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 98.19067501739735\n",
      "Training Loss Epoch: 0.06065408572194327\n",
      "Training Accuracy Epoch: 98.19067501739735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_np의 shape :  (100, 4311)\n",
      "pred_mean의 shape :  (4311,)\n",
      "Training Loss per 5000 steps: 0.004578258842229843\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.11032836220251348\n",
      "Training Accuracy per 5000 steps: 96.53193612774452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.65it/s]\n",
      "1it [00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 96.56692182788217\n",
      "Training Loss Epoch: 0.10923364863978052\n",
      "Training Accuracy Epoch: 96.56692182788217\n",
      "Training Loss per 5000 steps: 0.00527596240863204\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.0745260739499636\n",
      "Training Accuracy per 5000 steps: 97.60479041916167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.59it/s]\n",
      "1it [00:00,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 97.63395963813501\n",
      "Training Loss Epoch: 0.0738545567406763\n",
      "Training Accuracy Epoch: 97.63395963813501\n",
      "Training Loss per 5000 steps: 0.02387212961912155\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.053903288413824406\n",
      "Training Accuracy per 5000 steps: 98.12874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.61it/s]\n",
      "1it [00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 98.09788912085364\n",
      "Training Loss Epoch: 0.05376704354016266\n",
      "Training Accuracy Epoch: 98.09788912085364\n",
      "Training Loss per 5000 steps: 0.011077212169766426\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.05079848253404714\n",
      "Training Accuracy per 5000 steps: 98.35329341317366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:20,  6.70it/s]\n",
      "1it [00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 98.32985386221294\n",
      "Training Loss Epoch: 0.052585163251008725\n",
      "Training Accuracy Epoch: 98.32985386221294\n",
      "Training Loss per 5000 steps: 0.04721842333674431\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:12,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.055962988621245754\n",
      "Training Accuracy per 5000 steps: 98.45309381237524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.87it/s]\n",
      "1it [00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 98.42263975875667\n",
      "Training Loss Epoch: 0.0541102283169664\n",
      "Training Accuracy Epoch: 98.42263975875667\n",
      "Training Loss per 5000 steps: 0.004850995726883411\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.04942629951716469\n",
      "Training Accuracy per 5000 steps: 98.42814371257485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.76it/s]\n",
      "1it [00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 98.42263975875667\n",
      "Training Loss Epoch: 0.04922717325603209\n",
      "Training Accuracy Epoch: 98.42263975875667\n",
      "Training Loss per 5000 steps: 0.06682269275188446\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.04123099833567015\n",
      "Training Accuracy per 5000 steps: 98.90219560878243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.64it/s]\n",
      "1it [00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 98.8865692414753\n",
      "Training Loss Epoch: 0.040410903189158506\n",
      "Training Accuracy Epoch: 98.8865692414753\n",
      "Training Loss per 5000 steps: 0.004704025574028492\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.04195135188295493\n",
      "Training Accuracy per 5000 steps: 98.67764471057885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.58it/s]\n",
      "1it [00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 98.67780097425191\n",
      "Training Loss Epoch: 0.04115497033027085\n",
      "Training Accuracy Epoch: 98.67780097425191\n",
      "Training Loss per 5000 steps: 0.005335564725100994\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.053905130701628466\n",
      "Training Accuracy per 5000 steps: 98.22854291417165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:20,  6.71it/s]\n",
      "1it [00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 98.21387149153328\n",
      "Training Loss Epoch: 0.054353315826070864\n",
      "Training Accuracy Epoch: 98.21387149153328\n",
      "Training Loss per 5000 steps: 0.0035102625843137503\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.03980561158598443\n",
      "Training Accuracy per 5000 steps: 98.57784431137725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:20,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 98.63140802598005\n",
      "Training Loss Epoch: 0.038510927888141436\n",
      "Training Accuracy Epoch: 98.63140802598005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_np의 shape :  (100, 4311)\n",
      "pred_mean의 shape :  (4311,)\n",
      "Training Loss per 5000 steps: 0.0051600695587694645\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.03062820682957854\n",
      "Training Accuracy per 5000 steps: 98.97704590818363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.84it/s]\n",
      "1it [00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 99.00255161215495\n",
      "Training Loss Epoch: 0.029360323400892827\n",
      "Training Accuracy Epoch: 99.00255161215495\n",
      "Training Loss per 5000 steps: 0.012014628387987614\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.036392190717644025\n",
      "Training Accuracy per 5000 steps: 98.65269461077844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.61it/s]\n",
      "1it [00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 98.70099744838784\n",
      "Training Loss Epoch: 0.03641082905675673\n",
      "Training Accuracy Epoch: 98.70099744838784\n",
      "Training Loss per 5000 steps: 0.1352292150259018\n",
      "Training Accuracy per 5000 steps: 87.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.044425457993955884\n",
      "Training Accuracy per 5000 steps: 98.42814371257485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.59it/s]\n",
      "1it [00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 98.46903270702853\n",
      "Training Loss Epoch: 0.04371323620997489\n",
      "Training Accuracy Epoch: 98.46903270702853\n",
      "Training Loss per 5000 steps: 0.0010528101120144129\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.022342252078351794\n",
      "Training Accuracy per 5000 steps: 99.35129740518963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.55it/s]\n",
      "1it [00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 99.28090930178612\n",
      "Training Loss Epoch: 0.02362832196899396\n",
      "Training Accuracy Epoch: 99.28090930178612\n",
      "Training Loss per 5000 steps: 0.0005759387859143317\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.030003642205947343\n",
      "Training Accuracy per 5000 steps: 99.07684630738522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.55it/s]\n",
      "1it [00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 99.00255161215495\n",
      "Training Loss Epoch: 0.031487136817574396\n",
      "Training Accuracy Epoch: 99.00255161215495\n",
      "Training Loss per 5000 steps: 0.011698679998517036\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.03188338339777929\n",
      "Training Accuracy per 5000 steps: 99.15169660678643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.61it/s]\n",
      "1it [00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 99.1185339828346\n",
      "Training Loss Epoch: 0.0341333130773905\n",
      "Training Accuracy Epoch: 99.1185339828346\n",
      "Training Loss per 5000 steps: 0.014122704043984413\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.026381188224289594\n",
      "Training Accuracy per 5000 steps: 99.17664670658682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.61it/s]\n",
      "1it [00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 99.21131987937834\n",
      "Training Loss Epoch: 0.025643054579500394\n",
      "Training Accuracy Epoch: 99.21131987937834\n",
      "Training Loss per 5000 steps: 0.007187181152403355\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.039622937975642585\n",
      "Training Accuracy per 5000 steps: 98.82734530938124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.54it/s]\n",
      "1it [00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 98.8169798190675\n",
      "Training Loss Epoch: 0.03923175897046337\n",
      "Training Accuracy Epoch: 98.8169798190675\n",
      "Training Loss per 5000 steps: 0.0023683742620050907\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.02999843930665375\n",
      "Training Accuracy per 5000 steps: 99.05189620758483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.54it/s]\n",
      "1it [00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 99.04894456042682\n",
      "Training Loss Epoch: 0.03091711284105596\n",
      "Training Accuracy Epoch: 99.04894456042682\n",
      "Training Loss per 5000 steps: 0.0004913623561151326\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.016635925069573558\n",
      "Training Accuracy per 5000 steps: 99.47604790419162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 99.28090930178612\n",
      "Training Loss Epoch: 0.023884443470360263\n",
      "Training Accuracy Epoch: 99.28090930178612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_np의 shape :  (100, 4311)\n",
      "pred_mean의 shape :  (4311,)\n",
      "Training Loss per 5000 steps: 0.0007810007082298398\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:15,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.029358868270875662\n",
      "Training Accuracy per 5000 steps: 99.17664670658682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:21,  6.62it/s]\n",
      "1it [00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 99.02574808629089\n",
      "Training Loss Epoch: 0.03314953000779443\n",
      "Training Accuracy Epoch: 99.02574808629089\n",
      "Training Loss per 5000 steps: 0.0039537749253213406\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.02804697530271863\n",
      "Training Accuracy per 5000 steps: 99.20159680638723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.77it/s]\n",
      "1it [00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 99.18812340524241\n",
      "Training Loss Epoch: 0.027820517211979263\n",
      "Training Accuracy Epoch: 99.18812340524241\n",
      "Training Loss per 5000 steps: 0.016324251890182495\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:16,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.024715130047223432\n",
      "Training Accuracy per 5000 steps: 99.07684630738522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:22,  6.54it/s]\n",
      "1it [00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 99.09533750869868\n",
      "Training Loss Epoch: 0.02568692403266868\n",
      "Training Accuracy Epoch: 99.09533750869868\n",
      "Training Loss per 5000 steps: 0.00039126176852732897\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.03553786246931973\n",
      "Training Accuracy per 5000 steps: 98.75249500998004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.82it/s]\n",
      "1it [00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 98.65460450011598\n",
      "Training Loss Epoch: 0.03887011523363167\n",
      "Training Accuracy Epoch: 98.65460450011598\n",
      "Training Loss per 5000 steps: 0.0018505825428292155\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.021514289142005562\n",
      "Training Accuracy per 5000 steps: 99.42614770459082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.84it/s]\n",
      "1it [00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 99.39689167246578\n",
      "Training Loss Epoch: 0.023598234890058425\n",
      "Training Accuracy Epoch: 99.39689167246578\n",
      "Training Loss per 5000 steps: 0.0020069691818207502\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.026655616749569722\n",
      "Training Accuracy per 5000 steps: 99.12674650698602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.83it/s]\n",
      "1it [00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 5: 99.14173045697054\n",
      "Training Loss Epoch: 0.0265670974080091\n",
      "Training Accuracy Epoch: 99.14173045697054\n",
      "Training Loss per 5000 steps: 0.005182264372706413\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.01789580992079503\n",
      "Training Accuracy per 5000 steps: 99.57584830339322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.79it/s]\n",
      "1it [00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 6: 99.58246346555323\n",
      "Training Loss Epoch: 0.0182865914647021\n",
      "Training Accuracy Epoch: 99.58246346555323\n",
      "Training Loss per 5000 steps: 0.014313742518424988\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.01363344340001469\n",
      "Training Accuracy per 5000 steps: 99.50099800399201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.74it/s]\n",
      "1it [00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 7: 99.53607051728137\n",
      "Training Loss Epoch: 0.01297310774720724\n",
      "Training Accuracy Epoch: 99.53607051728137\n",
      "Training Loss per 5000 steps: 0.0003576861636247486\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.021218485600269028\n",
      "Training Accuracy per 5000 steps: 99.40119760479043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.85it/s]\n",
      "1it [00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 8: 99.42008814660171\n",
      "Training Loss Epoch: 0.021079198927713597\n",
      "Training Accuracy Epoch: 99.42008814660171\n",
      "Training Loss per 5000 steps: 0.00098221970256418\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.03594500431285552\n",
      "Training Accuracy per 5000 steps: 99.05189620758483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 9: 99.02574808629089\n",
      "Training Loss Epoch: 0.036294215412776214\n",
      "Training Accuracy Epoch: 99.02574808629089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_np의 shape :  (100, 4311)\n",
      "pred_mean의 shape :  (4311,)\n",
      "Training Loss per 5000 steps: 0.0008890603203326464\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.04089150070020499\n",
      "Training Accuracy per 5000 steps: 98.87724550898204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.79it/s]\n",
      "1it [00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 98.93296218974716\n",
      "Training Loss Epoch: 0.038736183574899004\n",
      "Training Accuracy Epoch: 98.93296218974716\n",
      "Training Loss per 5000 steps: 0.0007689392659813166\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.016108964319724754\n",
      "Training Accuracy per 5000 steps: 99.52594810379242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.81it/s]\n",
      "1it [00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 99.51287404314544\n",
      "Training Loss Epoch: 0.01593470923440701\n",
      "Training Accuracy Epoch: 99.51287404314544\n",
      "Training Loss per 5000 steps: 0.007374107372015715\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.016572789636909026\n",
      "Training Accuracy per 5000 steps: 99.47604790419162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:19,  6.81it/s]\n",
      "1it [00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 99.48967756900952\n",
      "Training Loss Epoch: 0.01660871093939702\n",
      "Training Accuracy Epoch: 99.48967756900952\n",
      "Training Loss per 5000 steps: 0.0009120951290242374\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.013381191376785371\n",
      "Training Accuracy per 5000 steps: 99.47604790419162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.83it/s]\n",
      "1it [00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 99.44328462073764\n",
      "Training Loss Epoch: 0.013866283783874564\n",
      "Training Accuracy Epoch: 99.44328462073764\n",
      "Training Loss per 5000 steps: 0.00034854907426051795\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:13,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.022687560444039096\n",
      "Training Accuracy per 5000 steps: 99.47604790419162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:18,  6.84it/s]\n",
      "1it [00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 99.48967756900952\n",
      "Training Loss Epoch: 0.02167683300559071\n",
      "Training Accuracy Epoch: 99.48967756900952\n",
      "Training Loss per 5000 steps: 0.0006244438118301332\n",
      "Training Accuracy per 5000 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [00:22,  6.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1b51dbae4b52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdil_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMC_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesting_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMC_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-45f88e4dab7b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, data_loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mbig_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mn_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcalcuate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbig_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dil_iter = 5\n",
    "MC_iter  = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "result = MC_predict(model,testing_loader,MC_iter)\n",
    "for i in range(dil_iter):\n",
    "    result_series = pd.Series(result)\n",
    "    dil_train = pd.DataFrame(test_df[\"Phrase\"])\n",
    "    dil_train[\"Sentiment\"] = result_series\n",
    "    \n",
    "    dil_loader   = get_data_loader(dil_train, tokenizer, max_len, batch_size, True, True)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch,dil_loader)\n",
    "    \n",
    "    result = MC_predict(model,testing_loader,MC_iter)\n",
    "    \n",
    "    submission = pd.DataFrame({'Id' : range(len(result)), 'Category' : result})\n",
    "    submission.to_csv('submission_T'+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_soft_predict(model,testing_loader,MC_num):\n",
    "    MC_pred = get_predictions(model, testing_loader)\n",
    "    for i in range(MC_num-1):\n",
    "        predictions = get_predictions(model, testing_loader)\n",
    "        MC_pred     += predictions\n",
    "    MC_pred = MC_pred/MC_num\n",
    "    result = torch.argmax(MC_pred, dim=1)\n",
    "    resulti = result.numpy()\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
